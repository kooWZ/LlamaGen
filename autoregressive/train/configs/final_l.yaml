dataset: "imagenet_code"
num_classes: 1000
code_path: "ImageNet-1k/final_codes/h5_dataset/"

auto_resume: true
# gpt_ckpt: "outputs/ckpts/92_1163523.pt"
results_dir: "outputs/final_semtok-1stage-L"
upload_to_hf: false

ema: false

gpt_model: "GPT-L"
gpt_type: "c2i"
vocab_size: 16384
cls_token_num: 1
dropout_p: 0.1
token_dropout_p: 0.1
drop_path_rate: 0.0
latent_size: 576
use_liger: false

no_compile: false

epochs: 300
global_batch_size: 1024
global_seed: 42
num_workers: 16
gradient_accumulation_steps: 1
mixed_precision: "bf16"
fp32_attention: true

max_grad_norm: 1
grad_norm_threshold: 10.0
check_grad_norm_for_skip: false

ckpt_every_epoch: 20
do_eval: true
# eval_every_iter: 20
reduce_grad_norm_every_iter: 1

lr: 1.0e-4
init_lr: 1.0e-6
final_lr: 1.2e-5
weight_decay: 5.0e-2
scheduler: "constant"
beta1: 0.9
beta2: 0.95
eps: 1.0e-6
warmup_epochs: 80

wandb_project: "LlamaGen"
wandb_run_name: "final_semtok-1stage-L"
wandb_tags: []
wandb_notes: null
wandb_entity: "koowz-FVL25"
wandb_key: null


decoder_type: "final"
vq_config: "/inspire/hdd/project/autoregressive-video-generation/pengwujian-240108120095/workspace/zijie/projects/postTok/configs/vfmtok-semtok.yaml"
vq_ckpt: "/inspire/hdd/project/autoregressive-video-generation/pengwujian-240108120095/workspace/zijie/projects/postTok/experiments/tokenizer/exp011-vfmtok-semtok-trainable-both/checkpoints/0250000.pth"
eval_per_gpu_batch_size: 64
eval_num_fid_samples: 50000
eval_gather_freq: 10
cfg_scale: 2
cfg_interval: -1
temperature: 1.0
top_k: 0
top_p: 1.0
decoder_timesteps: 25
decoder_guidance_scale: 15